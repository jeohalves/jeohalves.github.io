<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.4.0 for Hugo">
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Merriweather&family=Roboto+Mono&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Merriweather&family=Roboto+Mono&display=swap" media=print onload="this.media='all'">
<meta name=google-site-verification content="google83223a76a39bdeb8.html">
<meta name=author content="Jeovane Honório Alves">
<meta name=description content="Analysis of cancer and other pathological diseases, like the interstitial lung diseases (ILDs), is usually possible through Computed Tomography (CT) scans. To aid this, a preprocessing step of segmentation is performed to reduce the area to be analyzed, segmenting the lungs and removing unimportant regions. Generally, complex methods are developed to extract the lung region, also using hand-made feature extractors to enhance segmentation. With the popularity of deep learning techniques and its automated feature learning, we propose a lung segmentation approach using fully convolutional networks (FCNs) combined with fully connected conditional random fields (CRF), employed in many state-of-the-art segmentation works. Aiming to develop a generalized approach, the publicly available datasets from University Hospitals of Geneva (HUG) and VESSEL12 challenge were studied, including many healthy and pathological CT scans for evaluation. Experiments using the dataset individually, its trained model on the other dataset and a combination of both datasets were employed. Dice scores of 98.67%±0.94% for the HUG-ILD dataset and 99.19%±0.37% for the VESSEL12 dataset were achieved, outperforming works in the former and obtaining similar state-of-the-art results in the latter dataset, showing the capability in using deep learning approaches.">
<link rel=alternate hreflang=en-us href=https://jeohalves.github.io/publication/alves2018extracting/>
<meta name=theme-color content="#4caf50">
<script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.681e0cf4b5ed93d87b9a6d2f0d351fd2.css>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TTNHLTPLJ5"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(a,b){gtag('event','click',{event_category:'outbound',event_label:a,transport_type:'beacon',event_callback:function(){b!=='_blank'&&(document.location=a)}}),console.debug("Outbound link clicked: "+a)}function onClickCallback(a){if(a.target.tagName!=='A'||a.target.host===window.location.host)return;trackOutboundLink(a.target,a.target.getAttribute('target'))}gtag('js',new Date),gtag('config','G-TTNHLTPLJ5',{}),gtag('set',{cookie_flags:'SameSite=None;Secure'}),document.addEventListener('click',onClickCallback,!1)</script>
<script>(function(b,d,e,a,g){b[a]=b[a]||[],b[a].push({'gtm.start':(new Date).getTime(),event:'gtm.js'});var f=d.getElementsByTagName(e)[0],c=d.createElement(e),h=a!='dataLayer'?'&l='+a:'';c.async=!0,c.src='https://www.googletagmanager.com/gtm.js?id='+g+h,f.parentNode.insertBefore(c,f)})(window,document,'script','dataLayer','G-TTNHLTPLJ5')</script>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hu2fd54a4efa430e13c3b224d47d4b162d_18608_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hu2fd54a4efa430e13c3b224d47d4b162d_18608_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://jeohalves.github.io/publication/alves2018extracting/>
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:site" content="@jeohalves">
<meta property="twitter:creator" content="@jeohalves">
<meta property="og:site_name" content="Jeovane Honório Alves">
<meta property="og:url" content="https://jeohalves.github.io/publication/alves2018extracting/">
<meta property="og:title" content="Extracting Lungs from CT Images Using Fully Convolutional Networks | Jeovane Honório Alves">
<meta property="og:description" content="Analysis of cancer and other pathological diseases, like the interstitial lung diseases (ILDs), is usually possible through Computed Tomography (CT) scans. To aid this, a preprocessing step of segmentation is performed to reduce the area to be analyzed, segmenting the lungs and removing unimportant regions. Generally, complex methods are developed to extract the lung region, also using hand-made feature extractors to enhance segmentation. With the popularity of deep learning techniques and its automated feature learning, we propose a lung segmentation approach using fully convolutional networks (FCNs) combined with fully connected conditional random fields (CRF), employed in many state-of-the-art segmentation works. Aiming to develop a generalized approach, the publicly available datasets from University Hospitals of Geneva (HUG) and VESSEL12 challenge were studied, including many healthy and pathological CT scans for evaluation. Experiments using the dataset individually, its trained model on the other dataset and a combination of both datasets were employed. Dice scores of 98.67%±0.94% for the HUG-ILD dataset and 99.19%±0.37% for the VESSEL12 dataset were achieved, outperforming works in the former and obtaining similar state-of-the-art results in the latter dataset, showing the capability in using deep learning approaches."><meta property="og:image" content="https://jeohalves.github.io/publication/alves2018extracting/featured.png">
<meta property="twitter:image" content="https://jeohalves.github.io/publication/alves2018extracting/featured.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2022-02-12T00:00:00+00:00">
<meta property="article:modified_time" content="2018-10-15T00:00:00+00:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://jeohalves.github.io/publication/alves2018extracting/"},"headline":"Extracting Lungs from CT Images Using Fully Convolutional Networks","image":["https://jeohalves.github.io/publication/alves2018extracting/featured.png"],"datePublished":"2022-02-12T00:00:00Z","dateModified":"2018-10-15T00:00:00Z","author":{"@type":"Person","name":"Jeovane Honório Alves"},"publisher":{"@type":"Organization","name":"Jeovane Honório Alves","logo":{"@type":"ImageObject","url":"https://jeohalves.github.io/media/icon_hu2fd54a4efa430e13c3b224d47d4b162d_18608_192x192_fill_lanczos_center_3.png"}},"description":"Analysis of cancer and other pathological diseases, like the interstitial lung diseases (ILDs), is usually possible through Computed Tomography (CT) scans. To aid this, a preprocessing step of segmentation is performed to reduce the area to be analyzed, segmenting the lungs and removing unimportant regions. Generally, complex methods are developed to extract the lung region, also using hand-made feature extractors to enhance segmentation. With the popularity of deep learning techniques and its automated feature learning, we propose a lung segmentation approach using fully convolutional networks (FCNs) combined with fully connected conditional random fields (CRF), employed in many state-of-the-art segmentation works. Aiming to develop a generalized approach, the publicly available datasets from University Hospitals of Geneva (HUG) and VESSEL12 challenge were studied, including many healthy and pathological CT scans for evaluation. Experiments using the dataset individually, its trained model on the other dataset and a combination of both datasets were employed. Dice scores of 98.67%±0.94% for the HUG-ILD dataset and 99.19%±0.37% for the VESSEL12 dataset were achieved, outperforming works in the former and obtaining similar state-of-the-art results in the latter dataset, showing the capability in using deep learning approaches."}</script>
<title>Extracting Lungs from CT Images Using Fully Convolutional Networks | Jeovane Honório Alves</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=2da66e791eeaf4a0d72f3dff5314b0b2>
<script src=/js/wowchemy-init.min.8f76bdc9e086322ed5147724ebba3d06.js></script>
<div class=page-header>
<header class=header--fixed>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Jeovane Honório Alves</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Jeovane Honório Alves</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#about><span>Home</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#projects><span>Projects</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#featured><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/uploads/resume.pdf><span>CV</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</header>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>Extracting Lungs from CT Images Using Fully Convolutional Networks</h1>
<div class=article-metadata>
<div>
<span class=author-highlighted>
Jeovane Honório Alves</span>, <span>
Pedro Martins Moreira Neto</span>, <span>
Lucas Ferrari de Oliveira</span>
</div>
<span class=article-date>
October 2018
</span>
</div>
<div class="btn-links mb-3">
<a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/1804.10704 target=_blank rel=noopener>
PDF
</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/alves2018extracting/cite.bib>
Cite
</a>
<a class="btn btn-outline-primary btn-page-header" href=/project/medical_imaging/>
Project
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.1109/IJCNN.2018.8489223 target=_blank rel=noopener>
DOI
</a>
</div>
</div>
<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:348px>
<div style=position:relative>
<img src=/publication/alves2018extracting/featured_hu7e5f3db0a342044259bf15a925ef6a89_553089_720x2500_fit_q75_h2_lanczos_3.webp width=720 height=348 alt class=featured-image>
<span class=article-header-caption>Lungs segmented by our approch</span>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract>Analysis of cancer and other pathological diseases, like the interstitial lung diseases (ILDs), is usually possible through Computed Tomography (CT) scans. To aid this, a preprocessing step of segmentation is performed to reduce the area to be analyzed, segmenting the lungs and removing unimportant regions. Generally, complex methods are developed to extract the lung region, also using hand-made feature extractors to enhance segmentation. With the popularity of deep learning techniques and its automated feature learning, we propose a lung segmentation approach using fully convolutional networks (FCNs) combined with fully connected conditional random fields (CRF), employed in many state-of-the-art segmentation works. Aiming to develop a generalized approach, the publicly available datasets from University Hospitals of Geneva (HUG) and VESSEL12 challenge were studied, including many healthy and pathological CT scans for evaluation. Experiments using the dataset individually, its trained model on the other dataset and a combination of both datasets were employed. Dice scores of 98.67%±0.94% for the HUG-ILD dataset and 99.19%±0.37% for the VESSEL12 dataset were achieved, outperforming works in the former and obtaining similar state-of-the-art results in the latter dataset, showing the capability in using deep learning approaches.</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#1>
Conference paper
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9">In <em>2018 International Joint Conference on Neural Networks</em></div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=article-tags>
<a class="badge badge-light" href=/tag/lung/>lung</a>
<a class="badge badge-light" href=/tag/computed-tomography/>computed tomography</a>
<a class="badge badge-light" href=/tag/image-segmentation/>image segmentation</a>
<a class="badge badge-light" href=/tag/ilds/>ilds</a>
<a class="badge badge-light" href=/tag/deep-learning/>Deep Learning</a>
</div>
<div class=share-box>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://jeohalves.github.io/publication/alves2018extracting/&text=Extracting%20Lungs%20from%20CT%20Images%20Using%20Fully%20Convolutional%20Networks" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://jeohalves.github.io/publication/alves2018extracting/&t=Extracting%20Lungs%20from%20CT%20Images%20Using%20Fully%20Convolutional%20Networks" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=Extracting%20Lungs%20from%20CT%20Images%20Using%20Fully%20Convolutional%20Networks&body=https://jeohalves.github.io/publication/alves2018extracting/" target=_blank rel=noopener class=share-btn-email aria-label=envelope>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://jeohalves.github.io/publication/alves2018extracting/&title=Extracting%20Lungs%20from%20CT%20Images%20Using%20Fully%20Convolutional%20Networks" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=Extracting%20Lungs%20from%20CT%20Images%20Using%20Fully%20Convolutional%20Networks%20https://jeohalves.github.io/publication/alves2018extracting/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://jeohalves.github.io/publication/alves2018extracting/&title=Extracting%20Lungs%20from%20CT%20Images%20Using%20Fully%20Convolutional%20Networks" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
<div class="media author-card content-widget-hr">
<a href=https://jeohalves.github.io/><img class="avatar mr-3 avatar-circle" src="https://s.gravatar.com/avatar/6136f9470d0beb76ddef8b11269548a3?s=200" alt="Jeovane Honório Alves"></a>
<div class=media-body>
<h5 class=card-title><a href=https://jeohalves.github.io/>Jeovane Honório Alves</a></h5>
<h6 class=card-subtitle>Machine Learning Researcher</h6>
<p class=card-text>My research interests include neural architecture search, computer vision and medical image processing.</p>
<ul class=network-icon aria-hidden=true>
<li>
<a href=mailto:jeohalves@gmail.com>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href=https://twitter.com/jeohalves target=_blank rel=noopener>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://scholar.google.com/citations?user=bervpJsAAAAJ" target=_blank rel=noopener>
<i class="fas fa-graduation-cap"></i>
</a>
</li>
<li>
<a href=https://github.com/jeohalves target=_blank rel=noopener>
<i class="fab fa-github"></i>
</a>
</li>
<li>
<a href=https://www.linkedin.com/in/jhalves/ target=_blank rel=noopener>
<i class="fab fa-linkedin"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/Python.min.js crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script>
<script src=/js/wowchemy-headroom.1cb9e2fc8399acee94eab837265b73bf.js type=module></script>
<script src=/en/js/wowchemy.min.216188596c551a0582beb89fb0d646e2.js></script>
</body>
</html>